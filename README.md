# ğŸ“˜ Policy Document Navigator

An AI-powered chatbot that makes understanding complex policy documents effortless. Built for the GenAI For GenZ Challenge, this tool uses Retrieval-Augmented Generation (RAG) to help users extract information from policy PDFs through natural language questions.

## ğŸŒŸ Features

- **PDF Upload**: Simply upload any policy document in PDF format
- **Natural Language Queries**: Ask questions in plain English - no legal jargon needed
- **Accurate Answers**: Get precise answers extracted directly from your policy document
- **Fast Semantic Search**: Powered by FAISS vector similarity search for lightning-fast retrieval
- **Smart Compression**: Automatically compresses lengthy documents while preserving key information
- **User-Friendly Interface**: Built with Streamlit for an intuitive experience

## ğŸ› ï¸ Tech Stack

- **Python 3.8+**
- **Google Gemini 2.5 Flash**: Advanced AI model for intelligent response generation
- **FAISS**: Facebook AI Similarity Search for efficient vector retrieval
- **Sentence Transformers**: Semantic embeddings using all-MiniLM-L6-v2
- **Streamlit**: Interactive web application framework
- **PyPDF**: PDF text extraction
- **LangChain**: Text splitting utilities

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Google Gemini API key

## ğŸš€ Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd policy-navigator
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   
   Create a `.env` file in the project root:
   ```
   GEMINI_API_KEY=your_gemini_api_key_here
   ```

   To get a Gemini API key:
   - Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Create an API key
   - Copy it to your `.env` file

## ğŸ’» Usage

1. **Start the application**
   ```bash
   streamlit run app.py
   ```

2. **Upload a policy document**
   - Click "Browse files" or drag and drop a PDF file
   - Wait for the document to be processed

3. **Ask questions**
   - Type your question in the text area
   - Click "Get Answer"
   - Receive accurate answers based on the policy content

## ğŸ“– Example Questions

- "What is the remote work policy?"
- "How many vacation days do employees get?"
- "What are the eligibility criteria for health benefits?"
- "What is the procedure for requesting time off?"
- "Are there any guidelines about confidentiality?"

## ğŸ—ï¸ Project Structure

```
policy-navigator/
â”‚
â”œâ”€â”€ app.py                  # Streamlit web application
â”œâ”€â”€ rag_engine.py           # RAG implementation with FAISS and Gemini
â”œâ”€â”€ scaledown.py            # Text compression utility
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # Environment variables (not in repo)
â”œâ”€â”€ temp_uploads/           # Temporary PDF storage
â””â”€â”€ README.md              # Project documentation
```

## ğŸ”§ How It Works

1. **Document Processing**:
   - PDF is uploaded and text is extracted
   - Text is compressed to optimize processing
   - Document is split into manageable chunks (500 chars with 50 char overlap)

2. **Vector Indexing**:
   - Each text chunk is converted to embeddings using Sentence Transformers
   - Embeddings are stored in a FAISS index for fast similarity search

3. **Question Answering**:
   - User question is converted to an embedding
   - Top 10 most relevant text chunks are retrieved
   - Context and question are sent to Gemini AI
   - AI generates an accurate answer based only on the provided context

## ï¿½ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI          â”‚
â”‚   (User Interface)      â”‚
â”‚   - PDF Upload          â”‚
â”‚   - Question Input      â”‚
â”‚   - Answer Display      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PyPDF Reader          â”‚
â”‚   (Text Extraction)     â”‚
â”‚   - PDF parsing         â”‚
â”‚   - Page text extract   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ScaleDown API         â”‚
â”‚   (Compression Layer)   â”‚
â”‚   - 75% size reduction  â”‚
â”‚   - Fallback: truncate  â”‚
â”‚   (scaledown.py)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RecursiveTextSplitter â”‚
â”‚   (Chunking Layer)      â”‚
â”‚   - chunk_size: 500     â”‚
â”‚   - overlap: 50         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SentenceTransformer   â”‚
â”‚   (Embedding Model)     â”‚
â”‚   - all-MiniLM-L6-v2    â”‚
â”‚   - 384-dim vectors     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FAISS Index           â”‚
â”‚   (Vector Database)     â”‚
â”‚   - IndexFlatL2         â”‚
â”‚   - L2 distance search  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Engine            â”‚
â”‚   (Retrieval Logic)     â”‚
â”‚   - Question embedding  â”‚
â”‚   - Top-10 retrieval    â”‚
â”‚   - Context assembly    â”‚
â”‚   (rag_engine.py)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google Gemini 2.5     â”‚
â”‚   (LLM Generation)      â”‚
â”‚   - Context-based QA    â”‚
â”‚   - Policy grounding    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI          â”‚
â”‚   (Answer Display)      â”‚
â”‚   - Formatted response  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **UI Layer** | Streamlit | User interaction, file upload, Q&A interface |
| **Parser** | PyPDF | Extract text from policy PDF files |
| **Compression** | ScaleDown API | Reduce text size by 75% (cost optimization) |
| **Chunker** | LangChain Splitter | Split into 500-char chunks with 50-char overlap |
| **Embedder** | SentenceTransformer | Convert text to 384-dim vectors |
| **Vector DB** | FAISS | Store and search embeddings efficiently |
| **RAG Logic** | Custom (rag_engine) | Orchestrate retrieval + generation |
| **LLM** | Gemini 2.5 Flash | Generate grounded answers from context |

### Data Flow

**Indexing Pipeline (PDF â†’ Vectors):**
```
PDF â†’ PyPDF â†’ Raw Text â†’ ScaleDown â†’ Compressed Text â†’ 
Chunking â†’ Chunks â†’ Embedding â†’ Vectors â†’ FAISS
```

**Query Pipeline (Question â†’ Answer):**
```
Question â†’ Embedding â†’ Vector â†’ FAISS Search â†’ Top-10 Chunks â†’ 
Context + Question â†’ Gemini â†’ Answer â†’ Display
```

## ï¿½ğŸ¯ Use Cases

- **Employee Handbook Navigation**: Quickly find HR policies and procedures
- **Student Policy Queries**: Understand university guidelines and regulations
- **Legal Document Review**: Extract key information from contracts and agreements
- **Compliance Checks**: Verify policy adherence and requirements
- **Onboarding Support**: Help new members understand organizational policies

## ğŸ“ Configuration

The following parameters can be adjusted in `rag_engine.py`:

- **Chunk size**: Currently set to 500 characters
- **Chunk overlap**: Currently set to 50 characters
- **Top-k retrieval**: Currently retrieves 10 most relevant chunks
- **Embedding model**: Currently using "all-MiniLM-L6-v2"
- **LLM model**: Currently using "gemini-2.5-flash"

## ğŸ”’ Privacy & Security

- Uploaded PDFs are stored temporarily in `temp_uploads/` directory
- Documents are processed locally
- Only question context is sent to Gemini API
- Consider adding cleanup logic for production use

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:
- Report bugs
- Suggest new features
- Submit pull requests

## ğŸ“„ License

This project is created for the GenAI For GenZ Challenge.

## ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ for the GenAI For GenZ Challenge

## ğŸ™ Acknowledgments

- Google Gemini for powerful AI capabilities
- Streamlit for the amazing web framework
- FAISS for efficient similarity search
- The open-source community

## ğŸ“ Support

If you encounter any issues or have questions, please open an issue in the repository.

---

**Made with ğŸš€ by leveraging the power of AI to democratize access to policy information**
